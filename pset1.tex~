\documentclass[11pt]{article}
\newcommand{\F}{\mathcal{F}}
\newcommand{\K}{\mathcal{K}}
\newcommand{\intr}{\int_{-\infty}^{\infty}}
\usepackage{microtype}
\usepackage{enumitem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[margin=1in]{geometry}
\usepackage{enumitem}
\newcommand{\s}{\text{span}}
\newcommand{\etop}{(E^\top)^\top}
\newcommand{\io}{\int_0^1}
\renewcommand{\H}{\mathcal{H}}
\newcommand{\Ss}{S_1\cap S_2}
\newcommand{\PP}{P_1 P_2}
%\setlist{enumerate}{leftmargin=*}
\begin{document}
\begin{flushleft}
  Lewis Ho\\
  Functional Analysis\\
  Pset 1\\
  Collaborators: Anton, Thomas
\end{flushleft}

\subsubsection*{Problem 1}


$h_n \to 0$. Proof: suppose not, i.e. $\exists \varepsilon > 0$ s.t.
$\forall N > 0~\exists n \geq N$ where $||h_n|| > \varepsilon$. In which case
there are infinite $h_n$ with norms greater than $\varepsilon$ (simply make
each $n$ the next $N$ to generate the subsequence), and $\sum_n ||h_n||$ is
infinite.

\subsubsection*{Problem 2}
\begin{enumerate}
\item If 0 is in $E$, it's also in $\bar{E}$.
\item Let $u$ and $v$ be members of $\bar{E}$. By definition there exist
  sequences $u_n$ and $v_n$ $\in E$ converging to them. $u_n + v_n$
  is in $E$ (linearity), $u_n + v_n \to u + v$, therefore $u + v \in \bar{E}$.
\item Let $c \in \mathbb{F}$, $a \in \bar{E}$. There exists some sequence $a_n$
  converging to $a$ in $E$. $ca_n \in E$, thus $ca = \lim ca_n \in \bar{E}$. 
\end{enumerate}

\subsubsection*{Problem 3}

\paragraph{$(E^\top)^\top \subseteq \overline{\s}$:}
Let $v_n \to v \in \etop$.
Consider $v_n - Pv_n$, where $P$ is
projection onto the span. Let $w_i$ be orthogonal basis vectors for $E^\top$.
$(v_n - Pv_n, w_i) = (v_n, w_i) \to (v, w_i) = 0$, and $v_n - Pv_n \in E^\top$,
so $||v_n - Pv_n|| \to 0$. I.e. $Pv_n \in \s \to v$.

\paragraph{$\supseteq$:}
Let $v \in \overline{\s}~, v_n \to v$, with $v_n \in \s$. For any $w
\in E^\top$, $(v_n, w) = 0$, as $v_n$ are linear combinations of vectors
orthogonal to $w$. By continuity, $(v,w) = 0$.

\subsection*{Problem 4}
\begin{enumerate}
\item If $\sum|a_n|^2 < \infty$, $\exists \sup{a_n} = a$. $\|\sum a_nz^n\| \leq
  a\|\sum z^n\| \leq \infty$ for $|z| < 1$.
\item Linearity: $L(\alpha\{a_n\}+\beta\{b_n\}) = \sum(\alpha a_n + \beta b_n)
  \lambda^n = \alpha\sum a_n\lambda^n + \beta\sum b_n \lambda^n$.

  Bounded: let $a = \sup \{a_n\}$. $|L(\{a_n\})| \leq \sum|a\lambda^n| = 
  |a^2|^{\frac{1}{2}}\sum|\lambda^n| \leq \sum\lambda^n(\sum|a_n|^2)^{\frac{1}{2}}$.
\item $h = (\lambda, \lambda^2, \lambda^3,\ldots)$. $(h, h_0)$ is maximized at
  $h = h_0$, so $\|L\|=\frac{(h_0,h_0)}{\|h_0\|} = \|h_0\|$.
\end{enumerate}

\subsection*{Problem 5}
\begin{enumerate}[label=\alph*)]
\item Norm preservation:
  \begin{align*}
    \|U[F]\|
    &= \intr \frac{1}{\pi^{1/2}(i+x)}F\left(\frac{i-x}{i+x}\right)\overline{
      \frac{1}{\pi^{1/2}(i+x)}G\left(\frac{i-x}{i+x}\right)}dx\\
    &= \frac{1}{\pi}\intr\frac{1}{1+x^2}F\left(\frac{i-x}{i+x}\right)\overline{
      G\left(\frac{i-x}{i+x}\right)}dx\\
  \end{align*}
  Let $e^{i\pi} = \frac{i-x}{i+x}$. Note: $\frac{1}{1+x^2} = \frac{2}{x+i}\cdot
  \frac{i+x}{i-x}$, and thus $d\theta = \frac{-2}{(x+i)^2e^{i\theta}} = \frac{2}
    {1+x^2}$. Substituting, we get:
  \begin{displaymath}
    \|U[F]\|
    = \frac{1}{2\pi}\int_{-\pi}^{\pi}F(e^{i\pi})\overline{G(e^{i\pi})}d\theta =
    \|F\|.
  \end{displaymath}
  Bijectivity: combining the inverse maps $x\mapsto \frac{1-xi}{1+x}$ and $F
  \mapsto \pi^{1/2}(i+x)F$, we have our inverse mapping (both functions are
  defined everywhere):
  \begin{displaymath}
    F(x)\mapsto \pi^{1/2}(i+x)G\left(\frac{i - x}
      {1+x}\right)
  \end{displaymath}

  Thus our mapping is bijective and hence unitary.
\end{enumerate}

\subsection*{Problem 6}

\subsection*{Problem 7}
Suppose $A$ is bounded yet $\sup|\alpha_n|$ is infinite. Let $a_n$ be the
sequence such that $\alpha_{a_n} > n$. Clearly $|Ae_{a_n}| \to \infty$, i.e.
isn't bounded, a contradiction. Thus $A$ being bounded means $\sup|\alpha_n|$ is
finite. Conversely, suppose $\sup|\alpha_n| \leq M$. $\|Aa_n\| \leq \|Ma_n\| =
M\|a_n\|$, i.e. $A$ is bounded.

\subsection*{Problem 8}

Linearity follows from the linearity of integration and multiplication.
Boundedness:
\begin{align*}
  \|Af\|^2 &= \io\left|\io k(x,y)f(y)dy\right|^2dx\\
           &\leq \io\left( \io|k(x,y)|^2dy \io|\overline{f(y)}|^2dy \right)dx\\
           &= \|k\|^2\|f\|^2.
\end{align*}

\subsection*{Problem 9}

The subspace spanned by, say, polynomials on $[0,1]$ is dense in the subspace
of functions that vanish outside $[0,1]$, but it is not closed (as there are
clearly non-polynomial $L^2$ functions defined on $[0,1]$. Likewise with the
subspace of continuous square-integrable functions on $\mathbb{R}$, which is
dense in $L^2$ (and thus whose closure is $L^2(\mathbb{R})$)---note that not all
$L^2$ functions are equivalent to continuous functions, hence the subspace is not
itself closed.

\subsection*{Problem 10}

Lemma: $P_1P_2 = P_2P_1$ if and only if there exists an orthogonal basis $\{e_i\}$
such that a subset of it $\{e_{a_i}\}$ spans $S_1$ and another $\{e_{b_i}\}$ spans
$S_2$. $\Rightarrow$: let $h \in \H$, and write $h = \sum a_ie_i$. $P_1P_2h = P_1
\sum_{k \in \{b_i\}}a_ke_k = \sum_{k\in \{a_i\}\cap\{b_i\}}a_ke_k = P_2P_1h$.


$\Leftarrow$: let $\{b_i\}$ span $S_2$. For $k \notin S_1 \cap S_2$, $P_1P_2h = P_1
(\sum \alpha_i b_i) = P_1(\sum_{b_i \in P_1\cap P_2}\alpha_i b_i + \sum_{b_i\notin
  P_1\cap P_2}\alpha_i b_i) = Ph + k$, where $P$ is the projection onto the
intersection and $k \in S_2 - S_1$ is nonzero, else the basis
vectors are orthogonal. $P_2P_1h$ can be written into $Ph + j$, where $j \in S_1-
S_2$ is nonzero. Thus $P_1P_2 \neq P_2P_1$.
\bigskip

\noindent Proof of statement: if $P_1$ and $P_2$ commute, if $e_i$ are our basis,
and $h = \sum a_ie_i$, $P_1P_2h = \sum_{e_i\in P_1\cap P_2} a_i e_i$, and is clearly
the projection onto $S_1\cap S_2$. If they don't commute, given some $h \notin
S_1\cap S_2$, $\PP h = f + g$, where $f \in \Ss$, and $g \notin \Ss$. Thus it
cannot be a projection onto $\Ss$. 

\subsection*{Problem 11}
\begin{enumerate}[label=\alph*)]
\item
  \begin{displaymath}
    \F[\chi_{[-k_0,k_0]}] = \int_{-k_0}^{k_0}e^{i2\pi xy}dy
                          = \frac{e^{i2\pi xk_0}-e^{-i2\pi xk_0}}{2\pi i x}
                          = \frac{\sin(2\pi xk_0)}{\pi x}
  \end{displaymath}
\item We use the substitution $u = z-y$:
  \begin{displaymath}
    \intr K(x-z)K(z-y)dz = \intr K((x-y)-u)K(u)du = \F[\chi]*\F[\chi](x-y) =
    \F[\chi\cdot\chi](x-y)
  \end{displaymath}
  which is $K(x-y)$.
\item With Cauchy-Schwarz and the square integrability of $K$,
  \begin{displaymath}
    \|\K(f)\|^2 = \left| \int_{-\infty}^{\infty}K(x-y)f(y)dy\right|^2
    \leq \|K(x-y)\|^2\|f(x)\|^2.
  \end{displaymath}
\item
  \begin{align*}
    \K[\K[f]] &= \intr k(x-z) \intr k(z-y)f(y)dydz\\
              &= \intr\intr k(x-z)k(z-y)f(y)dydz\\
              &= \intr k(x-y)f(y)dy.
  \end{align*}
\item Linearity: because $\F$ is a linear operator, if $f$ and $g = 0$ at $x$,
  $\F[\alpha f + \beta g](x) = 0$ also, and thus the subspace is linear.
  Closedness: let $f_n \to f$ with $f_n \in \H_0$. Let $f_k$ be the subsequence
  that is dominated by $2f$, say. (Check that this is allowed). Thus at $|x| >
  k_0$, 
  \begin{align*}
    \intr e^{2\pi ixy}f_n(y)dy &= 0\\
    \lim_{n\to \infty}\intr e^{2\pi ixy}f_n(y)dy &= 0\\
    \intr e^{2\pi xy}f(y)dy = \F[f] &= 0.
  \end{align*}
\item Lemma: $F[K] = \F[\F[\chi_{[-k_0,k_0]}]] = \chi_{[-k_0,k_0]}$. Proof:
  \begin{displaymath}
    \intr e^{2\pi ixy}\frac{\sin(2\pi k_0y)}{\pi y}dx =
    -\int_{\infty}^{-\infty}e^{-2\pi i xz}\frac{\sin(2\pi k_0z)}{\pi z}dz =
    \F^{-1}[\F[\chi]].
  \end{displaymath}

  Lemma 2: for all $g \in \H_0$, $\K[g] = g$. Proof:
  \begin{displaymath}
    \K[g] = \F^{-1}[\F[K*g]] = \F^{-1}[\F[K]\cdot\F[g]] = \F^{-1}[\chi\cdot\F[g]].
  \end{displaymath}
  As $F[g] = 0$ for all $x \notin [-k_0,k_0]$, the last term = $\F^{-1}[\F[g]] =
  g$.

  Proof of statement: (note that $K(x) = K(-x)$) we show $f - \K[f]~\bot~g$ for
  all $g \in \H_0$.
  \begin{align*}
    \intr(f-\K[f])(x)g(x)dx &= \intr fg - \intr\intr K(x-y)f(y)dy\cdot g(x)dx\\
                            &= \intr fg - \intr\intr K(y-x)g(x)f(y)dxdy\\
                            &= \intr fg - \intr \K[g](y)f(y)dy = 0.
  \end{align*}
\end{enumerate}
\end{document}